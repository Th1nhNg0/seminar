{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>short_candidate_start</th>\n",
       "      <th>short_candidate</th>\n",
       "      <th>short_candidate_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Đất nước nào không có quân đội</td>\n",
       "      <td>có 23 quốc gia không có lực lượng quân đội, ba...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Costa Rica, Iceland, Panama, Micronesia, Quần ...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pháp tấn công xâm lược Việt Nam vào ngày tháng...</td>\n",
       "      <td>Raymondienne (hay Raymonde Dien) sinh ngày 13 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cờ vua còn có tên gọi nào khác</td>\n",
       "      <td>Cúp cờ vua thế giới là tên gọi một số giải đấu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Núi nào cao nhất châu âu</td>\n",
       "      <td>Đỉnh núi nằm ở phần trung tâm của dãy núi Đại ...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>núi Elbrus</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Những cây thánh giá tại ngọn đồi Thánh giá ở L...</td>\n",
       "      <td>Ngọn đồi Thánh giá (tiếng Litva: ) là địa điểm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "1                     Đất nước nào không có quân đội   \n",
       "2  Pháp tấn công xâm lược Việt Nam vào ngày tháng...   \n",
       "3                     Cờ vua còn có tên gọi nào khác   \n",
       "4                           Núi nào cao nhất châu âu   \n",
       "5  Những cây thánh giá tại ngọn đồi Thánh giá ở L...   \n",
       "\n",
       "                                                text  short_candidate_start  \\\n",
       "1  có 23 quốc gia không có lực lượng quân đội, ba...                   53.0   \n",
       "2  Raymondienne (hay Raymonde Dien) sinh ngày 13 ...                    NaN   \n",
       "3  Cúp cờ vua thế giới là tên gọi một số giải đấu...                    NaN   \n",
       "4  Đỉnh núi nằm ở phần trung tâm của dãy núi Đại ...                   73.0   \n",
       "5  Ngọn đồi Thánh giá (tiếng Litva: ) là địa điểm...                    NaN   \n",
       "\n",
       "                                     short_candidate  short_candidate_length  \n",
       "1  Costa Rica, Iceland, Panama, Micronesia, Quần ...                      73  \n",
       "2                                                NaN                       0  \n",
       "3                                                NaN                       0  \n",
       "4                                         núi Elbrus                      10  \n",
       "5                                                NaN                       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/zac2022_train_merged_final.json',encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "    df = pd.json_normalize(data,'data')\n",
    "\n",
    "# 2 trường hợp output là có hoặc không có câu trả lời\n",
    "df = df[(df['category'] == 'FULL_ANNOTATION') | (df['category'] == 'FALSE_LONG_ANSWER')]\n",
    "# độ dài của câu trả lời\n",
    "df['short_candidate_length'] = df['short_candidate'].apply(lambda x: len(x) if type(x) == str else 0)\n",
    "# remove col \n",
    "df = df.drop(['answer','title','is_long_answer','category','id'], axis=1)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>short_candidate</th>\n",
       "      <th>short_candidate_start</th>\n",
       "      <th>title</th>\n",
       "      <th>short_candidate_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khí hậu khác biệt theo từng vùng. Thung lũng F...</td>\n",
       "      <td>Bao nhiêu ngày mùa đông dưới 0 độ?</td>\n",
       "      <td>40 ngày</td>\n",
       "      <td>341</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kyrgyzstan là một trong hai trong số năm nước ...</td>\n",
       "      <td>Trước đây bảng chữ cái Kyrgyz được viết bằng n...</td>\n",
       "      <td>ký tự Ả Rập</td>\n",
       "      <td>510</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nói chung, tất cả mọi người trong nước đều hiể...</td>\n",
       "      <td>Phiên dịch được sử dụng cho ngôn ngữ nào?</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>276</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vận tải Kyrgyzstan ở tình trạng kém phát triển...</td>\n",
       "      <td>Các con đường ở Kyrgyzstan thường chịu ảnh hưở...</td>\n",
       "      <td>thường bị lở đất hay lở tuyết.</td>\n",
       "      <td>220</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Đại điện nhà trai là Hoàng hậu Elisabeth và Th...</td>\n",
       "      <td>Các vị thế của tòa án Berlin đối với Anh và Ng...</td>\n",
       "      <td>chống Anh và thân Nga</td>\n",
       "      <td>993</td>\n",
       "      <td>Viktoria, Hoàng hậu Đức</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Khí hậu khác biệt theo từng vùng. Thung lũng F...   \n",
       "1  Kyrgyzstan là một trong hai trong số năm nước ...   \n",
       "2  Nói chung, tất cả mọi người trong nước đều hiể...   \n",
       "3  Vận tải Kyrgyzstan ở tình trạng kém phát triển...   \n",
       "4  Đại điện nhà trai là Hoàng hậu Elisabeth và Th...   \n",
       "\n",
       "                                            question  \\\n",
       "0                 Bao nhiêu ngày mùa đông dưới 0 độ?   \n",
       "1  Trước đây bảng chữ cái Kyrgyz được viết bằng n...   \n",
       "2         Phiên dịch được sử dụng cho ngôn ngữ nào?    \n",
       "3  Các con đường ở Kyrgyzstan thường chịu ảnh hưở...   \n",
       "4  Các vị thế của tòa án Berlin đối với Anh và Ng...   \n",
       "\n",
       "                  short_candidate  short_candidate_start  \\\n",
       "0                         40 ngày                    341   \n",
       "1                     ký tự Ả Rập                    510   \n",
       "2                          Kyrgyz                    276   \n",
       "3  thường bị lở đất hay lở tuyết.                    220   \n",
       "4           chống Anh và thân Nga                    993   \n",
       "\n",
       "                     title  short_candidate_length  \n",
       "0               Kyrgyzstan                       7  \n",
       "1               Kyrgyzstan                      11  \n",
       "2               Kyrgyzstan                       6  \n",
       "3               Kyrgyzstan                      30  \n",
       "4  Viktoria, Hoàng hậu Đức                      21  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlqa_df = pd.read_csv('data/MLQA_V1_vi.csv')\n",
    "# rename column\n",
    "mlqa_df.rename(columns={'context':'text','answer':'short_candidate','answer_start':'short_candidate_start'}, inplace=True)\n",
    "mlqa_df['short_candidate_length'] = mlqa_df['short_candidate'].apply(lambda x: len(x) if type(x) == str else 0)\n",
    "print(len(mlqa_df))\n",
    "mlqa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, mlqa_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d1ba2e908474da8616cd061a0e5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23365 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ff7227d28d47ceabab79c463e3b02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format theo code copy :v\n",
    "dataset = datasets.Dataset.from_pandas(df)\n",
    "dataset = dataset.map(lambda example: {'answers': {'answer_start': [example['short_candidate_start']] if example['short_candidate_start']!=None else [],\n",
    "                                                           'text': [example['short_candidate']] if example['short_candidate']!=None else[]}})\n",
    "dataset = dataset.map(lambda example: {'context': example['text']}, batched=True, remove_columns='text')\n",
    "# drop columns that are not needed\n",
    "dataset = dataset.remove_columns(['short_candidate_start','title', 'short_candidate', 'short_candidate_length'])\n",
    "# split \n",
    "dataset = dataset.train_test_split(test_size=0.1,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Các dịch gì thường đi kèm với những triệu chứng này?',\n",
       " 'answers': {'answer_start': [219.0], 'text': ['khí hư trắng']},\n",
       " 'context': 'Nhiễm nấm âm đạo, là sự phát triển quá nhiều của nấm men trong âm đạo đến mức gây kích thích. Các triệu chứng phổ biến nhất là ngứa âm đạo, có thể đến mức nghiêm trọng. Các triệu chứng khác bao gồm đau rát khi đi tiểu, khí hư trắng và dày, thường không có mùi, đau khi quan hệ tình dục và đỏ tấy xung quanh âm đạo. Triệu chứng thường trở nên xấu đi trước kỳ kinh nguyệt của phụ nữ.Nhiễm nấm âm đạo là do sự phát triển quá nhiều của nấm Candida. Nấm men này thường xuất hiện trong âm đạo với số lượng nhỏ. Bệnh này không được phân loại như một bệnh truyền nhiễm qua đường tình dục, tuy nhiên, nó có thể xảy ra thường xuyên hơn đối với những phụ nữ thường xuyên hoạt động tình dục. Các yếu tố rủi ro bao gồm việc dùng thuốc kháng sinh, mang thai, bệnh tiểu đường, và HIV/AIDS. Chế độ ăn đường đơn cũng có thể gây nấm. Quần áo chật, loại đồ lót, vệ sinh cá nhân có vẻ không phải là các yếu tố gây bệnh. Chẩn đoán bệnh này bằng cách kiểm tra chất nhầy âm đạo. Do các triệu chứng của bệnh này tương tự như triệu chứng của các bệnh lây truyền qua đường tình dục, chlamydia và lậu, nên cần thực hiện các kiểm tra kỹ hơn nếu có thể.Mặc dù thiếu bằng chứng, việc mặc đồ lót bông và quần áo rộng thường được đề nghị như một biện pháp phòng ngừa bệnh. Bác sĩ khuyến cáo nên tránh thụt rửa âm đạo và nên sử dụng sản phẩm vệ sinh có mùi thơm. Điều trị bệnh này sử dụng thuốc chống nấm. Có thể dùng thuốc dạng kem chẳng hạn như clotrimazole hoặc uống thuốc như fluconazole. Các nhà khoa học chưa nghiên cứu được khả năng của probiotic chống nhiễm trùng cho bệnh này.Khoảng 75% phụ nữ có ít nhất một lần trong đời nhiễm nấm âm đạo trong khi gần 50% có ít nhất hai lần. Khoảng 5% phụ nữ có nhiều hơn ba lần nhiễm nấm trong một năm. Nó là nguyên nhân phổ biến thứ hai của viêm âm đạo, chỉ sau nhiễm khuẩn âm đạo.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "doc_stride = 128\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (\n",
    "                offsets[token_start_index][0] <= start_char\n",
    "                and offsets[token_end_index][1] >= end_char\n",
    "            ):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while (\n",
    "                    token_start_index < len(offsets)\n",
    "                    and offsets[token_start_index][0] <= start_char\n",
    "                ):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef7f82db8f14435b0af7e46a4c776e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a94451cfaad4610a0d8a69f8e945c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"model_2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 22944\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71700\n",
      "  Number of trainable parameters = 177264386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50d727f3a6b4308aee726463c9891d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ngoph\\Desktop\\zalo_ai\\e2eqa-train+public_test-v1\\train_model_reader.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ngoph/Desktop/zalo_ai/e2eqa-train%2Bpublic_test-v1/train_model_reader.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\transformers\\trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1506\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\transformers\\trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1749\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1752\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1753\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1754\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1755\u001b[0m ):\n\u001b[0;32m   1756\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\transformers\\trainer.py:2526\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2524\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2526\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m   2528\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\envs\\rs\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"model_2/saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "qa = pipeline('question-answering', model='model_2\\checkpoint-28391',device=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/zac2022_train_merged_final.json',encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "    df = pd.json_normalize(data,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL_ANNOTATION\n",
      "QUESTION: Thiên đường thuế là gì\n",
      "CONTEXT: 1. không đánh thuế hoặc thuế gần như bằng không. Thiên đường thuế biến nó thành nơi để những người không cư trú ở đó tránh khỏi phải đóng thuế cao ở nơi họ ở hay kinh doanh.\n",
      "is long answer: True\n",
      "{'score': 7.756276562104565e-18, 'start': 49, 'end': 65, 'answer': 'Thiên đường thuế'}\n",
      "\n",
      "FULL_ANNOTATION\n",
      "QUESTION: thái bình là một thành phố trực thuộc tỉnh nào\n",
      "CONTEXT: Ngày 12 tháng 12 năm 2013 , Thủ tướng Chính phủ ra Quyết định 2418 / QĐ-TTg công nhận Thành phố Thái Bình là đô thị loại II trực thuộc tỉnh Thái Bình .\n",
      "is long answer: True\n",
      "{'score': 0.9999990463256836, 'start': 135, 'end': 151, 'answer': 'tỉnh Thái Bình .'}\n",
      "\n",
      "FALSE_LONG_ANSWER\n",
      "QUESTION: Quốc gia nào là quốc gia đầu tiên đoạt chức vô địch Worldcup\n",
      "CONTEXT: Năm 1971, Franz Beckenbauer trở thành đội trưởng của đội tuyển quốc gia. Ông đã dẫn dắt đội tuyển đoạt chức vô địch châu Âu Euro 1972, khi đánh bại Liên Xô 3–0 trong trận chung kết.\n",
      "is long answer: False\n",
      "{'score': 6.5968207189697315e-21, 'start': 148, 'end': 155, 'answer': 'Liên Xô'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PARTIAL_ANNOTATION\n",
    "for c in ['PARTIAL_ANNOTATION','FULL_ANNOTATION','FALSE_LONG_ANSWER']:\n",
    "    print(c)\n",
    "    example = df[df['category'] == c].sample(1)\n",
    "    question = example['question'].values[0]\n",
    "    context = example['text'].values[0]\n",
    "    print('QUESTION:', question)\n",
    "    print('CONTEXT:', context)\n",
    "    print('is long answer:',example['is_long_answer'].values[0])\n",
    "    print(qa(question=question, context=context))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'nhà chiêm tinh thiên văn học nổi tiếng tycho brahe là người nước nào'\n",
    "context = 'B. - Tycho Brahe ( 1546-1601 ) , nhà thiên văn học người Đan Mạch . - Brahmagupta ( 598-668 ) , nhà thiên văn học người Ấn Độ .'\n",
    "qa(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba141c8d811672bca916348b96b465f0d8c36918c76b97082af4ef2ad5ae2a45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/zac2022_train_merged_final.json',encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "    df = pd.json_normalize(data,'data')\n",
    "\n",
    "# 2 trường hợp output là có hoặc không có câu trả lời\n",
    "df = df[(df['category'] == 'FULL_ANNOTATION') | (df['category'] == 'FALSE_LONG_ANSWER')]\n",
    "# độ dài của câu trả lời\n",
    "df['short_candidate_length'] = df['short_candidate'].apply(lambda x: len(x) if type(x) == str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>is_long_answer</th>\n",
       "      <th>short_candidate_start</th>\n",
       "      <th>short_candidate</th>\n",
       "      <th>answer</th>\n",
       "      <th>short_candidate_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c926e7b0717202618a10dd907d4b4c39</td>\n",
       "      <td>Đất nước nào không có quân đội</td>\n",
       "      <td></td>\n",
       "      <td>có 23 quốc gia không có lực lượng quân đội, ba...</td>\n",
       "      <td>FULL_ANNOTATION</td>\n",
       "      <td>True</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Costa Rica, Iceland, Panama, Micronesia, Quần ...</td>\n",
       "      <td>wiki/Danh_sách_quốc_gia_không_có_lực_lượng_vũ_...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d38ef5bf1fb82b410026ed82c8a44cae</td>\n",
       "      <td>Pháp tấn công xâm lược Việt Nam vào ngày tháng...</td>\n",
       "      <td>Raymondienne</td>\n",
       "      <td>Raymondienne (hay Raymonde Dien) sinh ngày 13 ...</td>\n",
       "      <td>FALSE_LONG_ANSWER</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6b5589a98fdccd208dc752bac853993</td>\n",
       "      <td>Cờ vua còn có tên gọi nào khác</td>\n",
       "      <td>Cúp cờ vua thế giới</td>\n",
       "      <td>Cúp cờ vua thế giới là tên gọi một số giải đấu...</td>\n",
       "      <td>FALSE_LONG_ANSWER</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82396a18fa9812bfec4d3ecb7ae60905</td>\n",
       "      <td>Núi nào cao nhất châu âu</td>\n",
       "      <td>Shkhara</td>\n",
       "      <td>Đỉnh núi nằm ở phần trung tâm của dãy núi Đại ...</td>\n",
       "      <td>FULL_ANNOTATION</td>\n",
       "      <td>True</td>\n",
       "      <td>73.0</td>\n",
       "      <td>núi Elbrus</td>\n",
       "      <td>wiki/Elbrus</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3aa14f786db9b824863bf6897800256d</td>\n",
       "      <td>Những cây thánh giá tại ngọn đồi Thánh giá ở L...</td>\n",
       "      <td>Đồi Thánh Giá</td>\n",
       "      <td>Ngọn đồi Thánh giá (tiếng Litva: ) là địa điểm...</td>\n",
       "      <td>FALSE_LONG_ANSWER</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "1  c926e7b0717202618a10dd907d4b4c39   \n",
       "2  d38ef5bf1fb82b410026ed82c8a44cae   \n",
       "3  b6b5589a98fdccd208dc752bac853993   \n",
       "4  82396a18fa9812bfec4d3ecb7ae60905   \n",
       "5  3aa14f786db9b824863bf6897800256d   \n",
       "\n",
       "                                            question                title  \\\n",
       "1                     Đất nước nào không có quân đội                        \n",
       "2  Pháp tấn công xâm lược Việt Nam vào ngày tháng...         Raymondienne   \n",
       "3                     Cờ vua còn có tên gọi nào khác  Cúp cờ vua thế giới   \n",
       "4                           Núi nào cao nhất châu âu              Shkhara   \n",
       "5  Những cây thánh giá tại ngọn đồi Thánh giá ở L...        Đồi Thánh Giá   \n",
       "\n",
       "                                                text           category  \\\n",
       "1  có 23 quốc gia không có lực lượng quân đội, ba...    FULL_ANNOTATION   \n",
       "2  Raymondienne (hay Raymonde Dien) sinh ngày 13 ...  FALSE_LONG_ANSWER   \n",
       "3  Cúp cờ vua thế giới là tên gọi một số giải đấu...  FALSE_LONG_ANSWER   \n",
       "4  Đỉnh núi nằm ở phần trung tâm của dãy núi Đại ...    FULL_ANNOTATION   \n",
       "5  Ngọn đồi Thánh giá (tiếng Litva: ) là địa điểm...  FALSE_LONG_ANSWER   \n",
       "\n",
       "   is_long_answer  short_candidate_start  \\\n",
       "1            True                   53.0   \n",
       "2           False                    NaN   \n",
       "3           False                    NaN   \n",
       "4            True                   73.0   \n",
       "5           False                    NaN   \n",
       "\n",
       "                                     short_candidate  \\\n",
       "1  Costa Rica, Iceland, Panama, Micronesia, Quần ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                         núi Elbrus   \n",
       "5                                                NaN   \n",
       "\n",
       "                                              answer  short_candidate_length  \n",
       "1  wiki/Danh_sách_quốc_gia_không_có_lực_lượng_vũ_...                      73  \n",
       "2                                                NaN                       0  \n",
       "3                                                NaN                       0  \n",
       "4                                        wiki/Elbrus                      10  \n",
       "5                                                NaN                       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f56086e93146f5be6fbe639d93b9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17359 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac59da3a61be47179b7d4a7402cbaefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format theo code copy :v\n",
    "dataset = datasets.Dataset.from_pandas(df)\n",
    "dataset = dataset.map(lambda example: {'answers': {'answer_start': [example['short_candidate_start']] if example['short_candidate_start']!=None else [],\n",
    "                                                           'text': [example['short_candidate']] if example['short_candidate']!=None else[]}})\n",
    "dataset = dataset.map(lambda example: {'context': example['text']}, batched=True, remove_columns='text')\n",
    "# drop columns that are not needed\n",
    "dataset = dataset.remove_columns(['answer','short_candidate_start', 'short_candidate', 'short_candidate_length','is_long_answer','category'])\n",
    "# split \n",
    "dataset = dataset.train_test_split(test_size=0.1,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'a2f6cc3520c2085d03d31edf0bed3ab3',\n",
       " 'question': 'xiêm la là quốc hiệu cũ của quốc gia nào',\n",
       " 'title': 'Xiêm',\n",
       " '__index_level_0__': 18909,\n",
       " 'answers': {'answer_start': [52.0], 'text': ['Thái Lan']},\n",
       " 'context': 'Xiêm còn gọi là Xiêm La là quốc hiệu chính thức của Thái Lan từ thời nhà Chakri được thành lập năm 1782 cho đến ngày 23 tháng 6 năm 1939 .'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][9911]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e4df4f2e354c698a400a66daf17626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f576f90fe994fb399dfd5ffbe869946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db36826ae4b342a7a9041e81969f9bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30d292666204a3ca99946653a6568dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bcb49cd2dc4428913c47cf47594510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "doc_stride = 128\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (\n",
    "                offsets[token_start_index][0] <= start_char\n",
    "                and offsets[token_end_index][1] >= end_char\n",
    "            ):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while (\n",
    "                    token_start_index < len(offsets)\n",
    "                    and offsets[token_start_index][0] <= start_char\n",
    "                ):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61ab4d102c446c88171d6325e25ef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e4f8cf91be4a7db37e81abf950078e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"model_2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"model_2/saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "qa = pipeline('question-answering', model='model_2\\checkpoint-28391',device=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/zac2022_train_merged_final.json',encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "    df = pd.json_normalize(data,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL_ANNOTATION\n",
      "QUESTION: Thiên đường thuế là gì\n",
      "CONTEXT: 1. không đánh thuế hoặc thuế gần như bằng không. Thiên đường thuế biến nó thành nơi để những người không cư trú ở đó tránh khỏi phải đóng thuế cao ở nơi họ ở hay kinh doanh.\n",
      "is long answer: True\n",
      "{'score': 7.756276562104565e-18, 'start': 49, 'end': 65, 'answer': 'Thiên đường thuế'}\n",
      "\n",
      "FULL_ANNOTATION\n",
      "QUESTION: thái bình là một thành phố trực thuộc tỉnh nào\n",
      "CONTEXT: Ngày 12 tháng 12 năm 2013 , Thủ tướng Chính phủ ra Quyết định 2418 / QĐ-TTg công nhận Thành phố Thái Bình là đô thị loại II trực thuộc tỉnh Thái Bình .\n",
      "is long answer: True\n",
      "{'score': 0.9999990463256836, 'start': 135, 'end': 151, 'answer': 'tỉnh Thái Bình .'}\n",
      "\n",
      "FALSE_LONG_ANSWER\n",
      "QUESTION: Quốc gia nào là quốc gia đầu tiên đoạt chức vô địch Worldcup\n",
      "CONTEXT: Năm 1971, Franz Beckenbauer trở thành đội trưởng của đội tuyển quốc gia. Ông đã dẫn dắt đội tuyển đoạt chức vô địch châu Âu Euro 1972, khi đánh bại Liên Xô 3–0 trong trận chung kết.\n",
      "is long answer: False\n",
      "{'score': 6.5968207189697315e-21, 'start': 148, 'end': 155, 'answer': 'Liên Xô'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PARTIAL_ANNOTATION\n",
    "for c in ['PARTIAL_ANNOTATION','FULL_ANNOTATION','FALSE_LONG_ANSWER']:\n",
    "    print(c)\n",
    "    example = df[df['category'] == c].sample(1)\n",
    "    question = example['question'].values[0]\n",
    "    context = example['text'].values[0]\n",
    "    print('QUESTION:', question)\n",
    "    print('CONTEXT:', context)\n",
    "    print('is long answer:',example['is_long_answer'].values[0])\n",
    "    print(qa(question=question, context=context))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'nhà chiêm tinh thiên văn học nổi tiếng tycho brahe là người nước nào'\n",
    "context = 'B. - Tycho Brahe ( 1546-1601 ) , nhà thiên văn học người Đan Mạch . - Brahmagupta ( 598-668 ) , nhà thiên văn học người Ấn Độ .'\n",
    "qa(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba141c8d811672bca916348b96b465f0d8c36918c76b97082af4ef2ad5ae2a45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
